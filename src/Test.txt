
def prepare_and_train_linear_regression_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a Linear Regression model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = LinearRegression()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_ridge_regression_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a Ridge Regression model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = Ridge()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_lasso_regression_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a Lasso Regression model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = Lasso()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_elastic_net_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a Elastic Net model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = ElasticNet()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_decision_tree_regressor_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a Decision Tree Regressor model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = DecisionTreeRegressor()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_random_forest_regressor_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a Random Forest Regressor model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = RandomForestRegressor()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_gradient_boosting_regressor_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a Gradient Boosting Regressor model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = GradientBoostingRegressor()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_xgboost_regressor_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a XGBoost Regressor model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = XGBRegressor()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_lightgbm_regressor_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a LightGBM Regressor model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = LGBMRegressor()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_svr_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a Support Vector Regressor model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = SVR()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_knn_regressor_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a K-Nearest Neighbors Regressor model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = KNeighborsRegressor()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_mlp_regressor_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a MLP Regressor model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = MLPRegressor(max_iter=1000)
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_logistic_regression_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a Logistic Regression model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = LogisticRegression()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_knn_classifier_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a K-Nearest Neighbors Classifier model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = KNeighborsClassifier()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_decision_tree_classifier_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a Decision Tree Classifier model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = DecisionTreeClassifier()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_random_forest_classifier_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a Random Forest Classifier model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = RandomForestClassifier()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_gradient_boosting_classifier_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a Gradient Boosting Classifier model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = GradientBoostingClassifier()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_xgboost_classifier_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a XGBoost Classifier model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = XGBClassifier()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_lightgbm_classifier_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a LightGBM Classifier model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = LGBMClassifier()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_svm_classifier_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a Support Vector Classifier model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = SVC()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_gaussian_nb_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a Gaussian Naive Bayes model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = GaussianNB()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_multinomial_nb_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a Multinomial Naive Bayes model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = MultinomialNB()
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_mlp_classifier_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """Trains a MLP Classifier model after splitting and scaling the data."""
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_scaled_train = MyScaler.fit_transform(x_train)
    x_scaled_test = MyScaler.transform(x_test)
    model = MLPClassifier(max_iter=1000)
    model.fit(x_scaled_train, y_train)
    return MyScaler, model, x_train, x_test, y_train, y_test

def prepare_and_train_random_forest_model(x, y, test_size=0.3, shuffle=True, random_state=0):
    """
    Splits the dataset, scales the features, and trains a Random Forest Regressor.
    """
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    MyScaler = StandardScaler()
    x_Scaled_train = MyScaler.fit_transform(x_train)
    x_Scaled_test = MyScaler.transform(x_test)
    RfModel = RandomForestRegressor(random_state=random_state)
    RfModel.fit(x_Scaled_train, y_train)
    return MyScaler, RfModel, x_train, x_test, y_train, y_test

def save_model_and_scaler(model, scaler, model_filename='model', scaler_filename='scaler', save_dir='Model'):
    """
    Saves the model and scaler to disk with a timestamped filename to ensure unique storage.

    This function:
    1. Generates a timestamp in the format "YYYY-MM-DD_HH-MM-SS".
    2. Saves the model and scaler to disk in the specified directory with the timestamped filenames.
    3. Prints the file paths where the model and scaler have been saved.

    Parameters:
    - model (sklearn model or similar): The trained machine learning model to be saved.
    - scaler (scikit-learn Scaler or similar): The scaler used to scale the features.
    - model_filename (str, optional): The base filename for the model (default is 'model').
    - scaler_filename (str, optional): The base filename for the scaler (default is 'scaler').
    - save_dir (str, optional): The directory where the model and scaler will be saved (default is 'Model').

    Returns:
    - None: This function saves the model and scaler to disk and prints the file paths.
    """
    # Generate timestamp with the format "YYYY-MM-DD_HH-MM-SS"
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    
    # Create the full paths with timestamp
    model_path = f'{save_dir}/{model_filename}_{timestamp}.pkl'
    scaler_path = f'{save_dir}/{scaler_filename}_{timestamp}.pkl'
    
    # Save the model and scaler with timestamped filenames
    joblib.dump(model, model_path)
    joblib.dump(scaler, scaler_path)
    
    print(f"Model saved as {model_path}")
    print(f"Scaler saved as {scaler_path}")

def predict(user_input,ModelPath,ScalerPath):
    """
    Makes a prediction using a pre-trained model and a saved scaler.

    This function:
    1. Loads the pre-trained model and scaler from the specified file paths.
    2. Converts the user input (in dictionary format) to a 2D array.
    3. Scales the input data using the loaded scaler.
    4. Returns the prediction result from the model based on the scaled input.

    Parameters:
    - user_input (dict): A dictionary containing feature names as keys and feature values as inputs for prediction.
    - ModelPath (str): The file path to the saved pre-trained model (in .pkl format).
    - ScalerPath (str): The file path to the saved scaler (in .pkl format) used to scale the input data.

    Returns:
    - result: The prediction made by the model based on the processed and scaled input data.

    Exceptions:
    - FileNotFoundError: If the model or scaler file is not found at the specified paths.
    - Any other errors during input processing, scaling, or prediction will be logged and raised.
    """
    Model = joblib.load(ModelPath)  # Load the trained model
    MyScaler = joblib.load(ScalerPath)  # Load the saved scaler
    # Convert dict to 2D array if needed
    input_array = np.array([list(user_input.values())])
    input_array=MyScaler.transform(input_array)
    result = Model.predict(input_array)
    return result    

def prepare_and_train_model(x, y, model_type, test_size=0.3, shuffle=True, random_state=0):
    """
    Generic function to split, scale, and train a machine learning model based on the selected type.

    Supported Models:
     Supervised Learning

     Regression Models:
    - linear_regression
    - ridge_regression
    - lasso_regression
    - elastic_net
    - decision_tree_regressor
    - random_forest_regressor
    - gradient_boosting_regressor
    - xgboost_regressor
    - lightgbm_regressor
    - catboost_regressor
    - svr
    - knn_regressor
    - mlp_regressor

     Classification Models:
    - logistic_regression
    - knn_classifier
    - decision_tree_classifier
    - random_forest_classifier
    - gradient_boosting_classifier
    - xgboost_classifier
    - lightgbm_classifier
    - catboost_classifier
    - svm_classifier
    - gaussian_nb
    - multinomial_nb
    - mlp_classifier

    Parameters:
    - x (array-like): Feature data
    - y (array-like): Target data
    - model_type (str): Model key from the above list
    - test_size (float): Proportion for test split
    - shuffle (bool): Whether to shuffle before splitting
    - random_state (int): Seed for reproducibility

    Returns:
    - scaler (StandardScaler): Scaler used to transform the features
    - model: Trained model
    - x_train, x_test, y_train, y_test: Split datasets
    """
    model_dict = {
        # Regression models
        "linear_regression": LinearRegression(),
        "ridge_regression": Ridge(),
        "lasso_regression": Lasso(),
        "elastic_net": ElasticNet(),
        "decision_tree_regressor": DecisionTreeRegressor(),
        "random_forest_regressor": RandomForestRegressor(),
        "gradient_boosting_regressor": GradientBoostingRegressor(),
        "xgboost_regressor": XGBRegressor(),
        "lightgbm_regressor": LGBMRegressor(),
        "svr": SVR(),
        "knn_regressor": KNeighborsRegressor(),
        "mlp_regressor": MLPRegressor(max_iter=1000),

        # Classification models
        "logistic_regression": LogisticRegression(),
        "knn_classifier": KNeighborsClassifier(),
        "decision_tree_classifier": DecisionTreeClassifier(),
        "random_forest_classifier": RandomForestClassifier(),
        "gradient_boosting_classifier": GradientBoostingClassifier(),
        "xgboost_classifier": XGBClassifier(),
        "lightgbm_classifier": LGBMClassifier(),
        "svm_classifier": SVC(),
        "gaussian_nb": GaussianNB(),
        "multinomial_nb": MultinomialNB(),
        "mlp_classifier": MLPClassifier(max_iter=1000),
    }

    if model_type not in model_dict:
        raise ValueError(f"Model '{model_type}' is not recognized. Please choose from:\n{list(model_dict.keys())}")

    model = model_dict[model_type]

    # Split and scale
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, shuffle=shuffle, random_state=random_state)
    scaler = StandardScaler()
    x_train_scaled = scaler.fit_transform(x_train)
    x_test_scaled = scaler.transform(x_test)

    # Train model
    model.fit(x_train_scaled, y_train)

    return scaler, model, x_train, x_test, y_train, y_test